{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d65df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8c252",
   "metadata": {},
   "source": [
    "## READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99883ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>component_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>short_description</th>\n",
       "      <th>long_description</th>\n",
       "      <th>assignee_name</th>\n",
       "      <th>reporter_name</th>\n",
       "      <th>resolution_category</th>\n",
       "      <th>resolution_code</th>\n",
       "      <th>status_category</th>\n",
       "      <th>status_code</th>\n",
       "      <th>update_date</th>\n",
       "      <th>quantity_of_votes</th>\n",
       "      <th>quantity_of_comments</th>\n",
       "      <th>resolution_date</th>\n",
       "      <th>bug_fix_time</th>\n",
       "      <th>severity_category</th>\n",
       "      <th>severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>Core</td>\n",
       "      <td>product_123</td>\n",
       "      <td>LogTraceException in ProposalUtils.toMethodNam...</td>\n",
       "      <td>The following incident was reported via the au...</td>\n",
       "      <td>recommenders-inbox</td>\n",
       "      <td>error-reports-inbox</td>\n",
       "      <td>fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-29</td>\n",
       "      <td>Engine</td>\n",
       "      <td>product_120</td>\n",
       "      <td>CCE in DecorationNodeImpl.eSet (159)</td>\n",
       "      <td>The following incident was reported via the au...</td>\n",
       "      <td>serg.boyko2011</td>\n",
       "      <td>error-reports-inbox</td>\n",
       "      <td>fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>resolved</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>Compendium</td>\n",
       "      <td>product_52</td>\n",
       "      <td>[http servlet] During dispatching javax.servle...</td>\n",
       "      <td>Original issue https://issues.liferay.com/brow...</td>\n",
       "      <td>raymond.auge</td>\n",
       "      <td>raymond.auge</td>\n",
       "      <td>fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>resolved</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  creation_date component_name product_name  \\\n",
       "0    2015-05-22           Core  product_123   \n",
       "1    2015-03-29         Engine  product_120   \n",
       "2    2018-01-20     Compendium   product_52   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  LogTraceException in ProposalUtils.toMethodNam...   \n",
       "1               CCE in DecorationNodeImpl.eSet (159)   \n",
       "2  [http servlet] During dispatching javax.servle...   \n",
       "\n",
       "                                    long_description       assignee_name  \\\n",
       "0  The following incident was reported via the au...  recommenders-inbox   \n",
       "1  The following incident was reported via the au...      serg.boyko2011   \n",
       "2  Original issue https://issues.liferay.com/brow...        raymond.auge   \n",
       "\n",
       "         reporter_name resolution_category  resolution_code status_category  \\\n",
       "0  error-reports-inbox               fixed                1          closed   \n",
       "1  error-reports-inbox               fixed                1        resolved   \n",
       "2         raymond.auge               fixed                1        resolved   \n",
       "\n",
       "   status_code update_date  quantity_of_votes  quantity_of_comments  \\\n",
       "0            6  2015-05-27                  0                     2   \n",
       "1            4  2015-04-01                  0                     8   \n",
       "2            4  2018-01-22                  0                     3   \n",
       "\n",
       "  resolution_date  bug_fix_time severity_category  severity_code  \n",
       "0      2015-05-27             5            normal              2  \n",
       "1      2015-03-31             2            normal              2  \n",
       "2      2018-01-22             2            normal              2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da698843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_CLASSES 173\n"
     ]
    }
   ],
   "source": [
    "print(\"UNIQUE_CLASSES\",df.product_name.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494a5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.creation_date=pd.to_datetime(df.creation_date)\n",
    "df.update_date=pd.to_datetime(df.update_date)\n",
    "df.resolution_date = pd.to_datetime(df.resolution_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83959fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"]=df.creation_date.apply(lambda x :x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723f49e",
   "metadata": {},
   "source": [
    "#### FEATURES & Intuition behind why they are included or not in training: \n",
    "\n",
    "* **creation_date**\n",
    "    * Date at which bug was reported for the product\n",
    "    * Don't seems relevant to product \n",
    "\n",
    "\n",
    "* **update_date**\n",
    "    * Data at which any update was made for the bug (comment or anything)\n",
    "    * Don't seems relevant to product, depends on tester\n",
    "\n",
    "\n",
    "* **resolution_date**\n",
    "    * Issue resolution date\n",
    "    * Don't seems relevant to product, depends on tester\n",
    "    \n",
    "\n",
    "* **component_name** \n",
    "    * Component related to product which had bug\n",
    "    * Used as a feature to train model\n",
    "    * Seems relevant to product info\n",
    "    \n",
    "\n",
    "* **short_description**\n",
    "    * short desctiption of bug found by reporter\n",
    "    * Used as a feature to train model\n",
    "    \n",
    "\n",
    "* **long_description**\n",
    "    * Complete desctiption with error message & codes of bug \n",
    "    * Used as a feature to train model\n",
    "    \n",
    "\n",
    "* **assignee_name**\n",
    "     * To whom issue was assign to.\n",
    "     * can be a random person name, this feature will just add noise to data. No correlation at all.\n",
    "     * Not used in training\n",
    "     \n",
    "\n",
    "* **reporter_name**\n",
    "     * Reporter of issue\n",
    "     * can be a random person name, this feature will just add noise to data. No correlation at all.\n",
    "     * Not used in training\n",
    "     \n",
    "\n",
    "* **resolution_category**\n",
    "    * Only Unique value is `Fixed`. Doesn;t add any info for model\n",
    "    * Not used in training\n",
    "    \n",
    "\n",
    "* **resolution_code**\n",
    "    * Interger reperesentaion on resolution_category\n",
    "    * Not used in training\n",
    "    \n",
    "\n",
    "* **status_category**\n",
    "    * 2 values `closed` OR `resolved` \n",
    "    * Not related to product name, it is changed by assignee or reporter. \n",
    "    * Even after using it as a feature to train, I found it was not adding any relevant gain to metrics\n",
    "    * Not used in training\n",
    "    \n",
    "     \n",
    "* **status_code**\n",
    "    * Interger reperesentaion on status_category\n",
    "    * Not used in training\n",
    "    \n",
    "\n",
    "* **quantity_of_votes**\n",
    "    * Number of votes to bugs maybe \n",
    "    * Not related to product name, it is changed by assignee or reporter. \n",
    "    * Even after using it as a feature to train, I found it was not adding any relevant gain to metrics\n",
    "    * Not used in training\n",
    "    \n",
    "\n",
    "* **quantity_of_comments**\n",
    "    * Number of comments to bugs maybe \n",
    "    * Not related to product name, it is changed by assignee or reporter. \n",
    "    * Even after using it as a feature to train, I found it was not adding any relevant gain to metrics\n",
    "    * Not used in training\n",
    "    \n",
    "\n",
    "* **bug_fix_time**\n",
    "    * creation_date - resolution_date \n",
    "    * Not usefull in describeing product info, can be random because of availabity of tester's time.\n",
    "    * Even after using it as a feature to train, I found it was not adding any relevant gain to metrics\n",
    "    * Not used in training\n",
    "    \n",
    "    \n",
    "* **severity_category**\n",
    "    * Category of the issue : `['normal', 'blocker', 'trivial', 'minor', 'major', 'critical']`\n",
    "    \n",
    "\n",
    "* **severity_code**\n",
    "    * Interge reperesentaion on severity_category\n",
    "    * Code `2` is used for both `normal` & `minor` , which don;t seems right. \n",
    "\n",
    "\n",
    "* **product_name** \n",
    "    * label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d435325",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeab33a",
   "metadata": {},
   "source": [
    "#### Tokenizer to split descriptions &  error messages\n",
    "\n",
    "\n",
    "* removing `[]` from certain words like [http servlet] which helps in tfidf vectorizer. Other tfidf vectorizer would treat `html` & `[html` as separate words.\n",
    "\n",
    "* Tried lemmatizer & stemmer but didn't help in imporving metrics so didn't included in final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bb2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text): \n",
    "    tokens=[]\n",
    "    for token in text.split(\" \"):\n",
    "        tmp=[ (sub_word) for _token in token.split(\".\") for sub_word in _token.split(\"_\")]\n",
    "        tokens.extend(tmp)                    \n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e165c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"short_description\"] = df.short_description.apply(lambda x : re.sub(r'[\\[\\]]',\"\" ,x))\n",
    "df[\"short_description\"] = df.short_description.apply(custom_tokenizer)\n",
    "df.long_description=  df.long_description.fillna(\" NONE \")\n",
    "df.long_description = df.long_description.apply(lambda x : re.sub(r'[\\[\\]]',\"\" ,x))\n",
    "df.long_description = df.long_description.apply(custom_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0d678",
   "metadata": {},
   "source": [
    "## created encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb51667",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict_component_name={j.lower() :i+1  for i, j in enumerate(df[\"component_name\"].unique())}\n",
    "map_dict={j :i+1  for i, j in enumerate(df[\"severity_category\"].unique())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab413b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 1,\n",
       " 'blocker': 2,\n",
       " 'trivial': 3,\n",
       " 'minor': 4,\n",
       " 'major': 5,\n",
       " 'critical': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ea066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"severity_category\"]= df.severity_category.map(map_dict)\n",
    "df[\"component_name\"]= df.component_name.apply(lambda x: x.lower())\n",
    "df[\"component_name\"]= df.component_name.map(map_dict_component_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acca510",
   "metadata": {},
   "source": [
    "### Joined  short_description & long_description for tfidf vector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd09a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df.apply(lambda x: \"SHORT DESCRIPTION \" + x[\"short_description\"]+\\\n",
    "                        \". LONG DESCRIPTION \"  + x[\"long_description\"] , axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c4f9e",
   "metadata": {},
   "source": [
    "## Created Train test_split using stratify sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f08be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_in_train = df.product_name.value_counts()[df.product_name.value_counts()<10].index\n",
    "update_train=df[df.product_name.isin(append_in_train)]\n",
    "df=df[~df.product_name.isin(append_in_train)]\n",
    "train_df , test_df = train_test_split(df,test_size=0.2,stratify=df.product_name,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392e0f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7600, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea61462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7876, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.concat([train_df,update_train])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7e775",
   "metadata": {},
   "source": [
    "##  Creating text based features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d73954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(stop_words=\"english\",analyzer=\"word\", ngram_range=(1,1) , min_df=4 ,max_df=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fbb0863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7876x8054 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 285424 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_vec=tf_vect.fit_transform(train_df.text,)\n",
    "train_tf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4be220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf_vec = tf_vect.transform(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bf6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['creation_date', 'component_name', 'product_name', 'short_description',\n",
       "       'long_description', 'assignee_name', 'reporter_name',\n",
       "       'resolution_category', 'resolution_code', 'status_category',\n",
       "       'status_code', 'update_date', 'quantity_of_votes',\n",
       "       'quantity_of_comments', 'resolution_date', 'bug_fix_time',\n",
       "       'severity_category', 'severity_code', 'year', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea393c4",
   "metadata": {},
   "source": [
    "## Adding Tablular features to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd4a2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_name</th>\n",
       "      <th>severity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8019</th>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      component_name  severity_category\n",
       "5131              33                  1\n",
       "1346              87                  5\n",
       "8019             144                  6\n",
       "3034              35                  1\n",
       "6120             231                  1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_feature = ['component_name',  'severity_category']\n",
    "train_df[tab_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f38bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat=np.hstack(( train_df[tab_feature].values ,\\\n",
    "         train_tf_vec.toarray()\n",
    "       ))\n",
    "\n",
    "test_feat=np.hstack(( test_df[tab_feature].values ,\\\n",
    "         test_tf_vec.toarray()\n",
    "       ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c961c",
   "metadata": {},
   "source": [
    "## Building Random Forest classifier with class_wieght for imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9dab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier( n_estimators=50, random_state = 42,class_weight=\"balanced\",max_depth=300)\n",
    "rf.fit(train_feat,train_df.product_name)\n",
    "preds=rf.predict(test_feat )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f30c7",
   "metadata": {},
   "source": [
    "##  Metric \n",
    "\n",
    "* `accuracy : 62`\n",
    "* `weighted_Precision : 67` \n",
    "* `weighted_Recall : 62`\n",
    "* `weighted_F1_score : 61`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7c772b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   product_1       1.00      0.20      0.33         5\n",
      "  product_10       0.79      0.87      0.83       110\n",
      " product_100       1.00      0.00      0.00         3\n",
      " product_101       1.00      0.00      0.00         4\n",
      " product_103       1.00      0.60      0.75         5\n",
      " product_104       0.80      0.57      0.67         7\n",
      " product_105       1.00      0.33      0.50         3\n",
      " product_106       0.62      0.73      0.67        11\n",
      " product_107       0.00      1.00      0.00         0\n",
      " product_108       0.80      0.67      0.73         6\n",
      " product_109       0.57      0.67      0.62         6\n",
      "  product_11       0.00      1.00      0.00         0\n",
      " product_110       0.78      0.64      0.70        59\n",
      " product_111       1.00      0.50      0.67         2\n",
      " product_113       0.60      0.84      0.70        50\n",
      " product_114       1.00      0.00      0.00         6\n",
      " product_115       0.67      0.60      0.63        55\n",
      " product_116       0.77      0.61      0.68        33\n",
      " product_117       0.51      0.75      0.61       262\n",
      " product_118       0.50      0.22      0.31        18\n",
      " product_119       0.00      1.00      0.00         0\n",
      "  product_12       1.00      0.00      0.00         2\n",
      " product_120       1.00      1.00      1.00         7\n",
      " product_121       0.90      0.73      0.81        26\n",
      " product_122       0.00      1.00      0.00         0\n",
      " product_123       0.00      1.00      0.00         0\n",
      " product_126       0.50      0.20      0.29         5\n",
      " product_128       0.60      0.43      0.50         7\n",
      " product_129       1.00      0.38      0.55         8\n",
      " product_130       0.00      1.00      0.00         0\n",
      " product_131       1.00      0.33      0.50         9\n",
      " product_133       0.75      0.75      0.75         8\n",
      " product_134       0.00      1.00      0.00         0\n",
      " product_135       0.00      0.00      0.00         2\n",
      " product_136       0.00      1.00      0.00         0\n",
      " product_137       0.67      1.00      0.80         2\n",
      " product_138       0.50      0.67      0.57         3\n",
      " product_139       0.64      0.90      0.75        10\n",
      " product_140       1.00      0.50      0.67         4\n",
      " product_141       0.88      0.74      0.80        19\n",
      " product_142       1.00      0.50      0.67         6\n",
      " product_144       1.00      0.29      0.44         7\n",
      " product_145       0.67      0.50      0.57         4\n",
      " product_146       0.81      0.61      0.69        28\n",
      " product_147       1.00      0.50      0.67         2\n",
      " product_148       0.50      0.25      0.33         4\n",
      " product_152       0.00      1.00      0.00         0\n",
      " product_153       0.67      0.22      0.33         9\n",
      " product_154       1.00      0.62      0.77         8\n",
      " product_155       0.00      1.00      0.00         0\n",
      " product_157       1.00      0.25      0.40         4\n",
      "  product_16       1.00      0.75      0.86         4\n",
      " product_161       1.00      0.08      0.14        13\n",
      " product_163       0.00      1.00      0.00         0\n",
      " product_164       0.83      0.92      0.87        26\n",
      " product_165       0.00      0.00      0.00         7\n",
      " product_166       0.53      0.69      0.60        13\n",
      " product_167       0.81      0.45      0.58        29\n",
      " product_168       0.69      0.56      0.62        16\n",
      "  product_17       0.75      0.66      0.70        94\n",
      " product_170       0.80      0.67      0.73         6\n",
      " product_171       0.00      1.00      0.00         0\n",
      " product_173       0.45      0.74      0.56       196\n",
      "  product_20       0.61      0.54      0.57       106\n",
      "  product_21       0.67      0.60      0.63        10\n",
      "  product_23       0.90      0.43      0.58        21\n",
      "  product_24       0.00      0.00      0.00         2\n",
      "  product_25       0.67      0.33      0.44         6\n",
      "  product_27       0.00      0.00      0.00         3\n",
      "  product_29       1.00      0.50      0.67         8\n",
      "   product_3       1.00      0.62      0.77         8\n",
      "  product_31       0.70      0.61      0.65        38\n",
      "  product_32       1.00      0.00      0.00         3\n",
      "  product_33       0.50      0.21      0.30        14\n",
      "  product_35       0.67      1.00      0.80         2\n",
      "  product_36       0.00      0.00      0.00         7\n",
      "  product_37       1.00      0.00      0.00         2\n",
      "  product_38       0.77      0.62      0.69        16\n",
      "  product_39       0.78      0.35      0.48        20\n",
      "   product_4       0.00      1.00      0.00         0\n",
      "  product_40       0.00      0.00      0.00         2\n",
      "  product_41       0.00      1.00      0.00         0\n",
      "  product_42       0.00      1.00      0.00         0\n",
      "  product_43       0.75      0.60      0.67        10\n",
      "  product_44       0.25      0.33      0.29         3\n",
      "  product_46       1.00      0.67      0.80         3\n",
      "  product_49       0.92      0.48      0.63        23\n",
      "  product_50       1.00      0.17      0.29         6\n",
      "  product_51       1.00      0.00      0.00         3\n",
      "  product_52       0.80      0.52      0.63        62\n",
      "  product_53       1.00      0.00      0.00         3\n",
      "  product_55       0.29      0.12      0.17        16\n",
      "  product_57       0.00      1.00      0.00         0\n",
      "  product_58       0.00      1.00      0.00         0\n",
      "  product_61       0.75      0.46      0.57        13\n",
      "  product_62       0.55      0.50      0.52        12\n",
      "  product_67       0.00      1.00      0.00         0\n",
      "  product_68       1.00      0.83      0.91         6\n",
      "  product_69       0.58      0.69      0.63        88\n",
      "   product_7       0.80      0.86      0.83        14\n",
      "  product_70       0.86      0.68      0.76        28\n",
      "  product_71       1.00      0.25      0.40         4\n",
      "  product_72       0.70      0.78      0.74         9\n",
      "  product_74       1.00      0.71      0.83         7\n",
      "  product_75       0.00      0.00      0.00         2\n",
      "  product_77       1.00      0.00      0.00         2\n",
      "  product_78       0.71      0.23      0.34        22\n",
      "  product_79       0.33      0.17      0.22         6\n",
      "   product_8       1.00      0.50      0.67         2\n",
      "  product_80       0.00      0.00      0.00         2\n",
      "  product_83       0.75      0.75      0.75         4\n",
      "  product_84       0.00      1.00      0.00         0\n",
      "  product_87       1.00      1.00      1.00         2\n",
      "  product_89       0.57      0.80      0.67         5\n",
      "   product_9       0.33      0.25      0.29         4\n",
      "  product_90       0.50      0.40      0.44         5\n",
      "  product_91       0.64      0.50      0.56        28\n",
      "  product_93       0.00      1.00      0.00         0\n",
      "  product_96       0.75      0.60      0.67         5\n",
      "  product_98       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62      1900\n",
      "   macro avg       0.60      0.55      0.41      1900\n",
      "weighted avg       0.67      0.62      0.61      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df.product_name,preds,zero_division=1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1897d60",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e25a1c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APP/app/models/component_name_mapping.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib \n",
    "# joblib.dump(rf,\"APP/app/models/model.pkl\")\n",
    "# joblib.dump(tf_vect,\"APP/app/models/tf_vectorizer.pkl\")\n",
    "# joblib.dump(map_dict,\"APP/app/models/severity_category_mapping.pkl\")\n",
    "# joblib.dump(map_dict_component_name,\"APP/app/models/component_name_mapping.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a34905",
   "metadata": {},
   "source": [
    "## Instruction to run API\n",
    "\n",
    "* USING DOCKER\n",
    "    * cd project\n",
    "    * docker-compose build\n",
    "    * docker-compose up\n",
    "    * http://localhost:8000/docs\n",
    "* USING PYTHON\n",
    "    * cd project\n",
    "    * pip install -r requirements.txt\n",
    "    * from folder project -> cd app\n",
    "    * python main_app.py \n",
    "    * http://localhost:8000/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1fdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
